{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f96644-74d3-4d63-830c-8470fd2224d6",
   "metadata": {},
   "source": [
    "## Cookbook for Video Understanding with Seed-1.8\n",
    "\n",
    "Seed-1.8 offers strong video understanding and reasoning capabilities including video temporal grounding, spatiotemporal grounding, video reasoning, and long video understanding.\n",
    "\n",
    "Compared to the Seed1.5-VL, the Seed-1.8 reduces the number of tokens per video frame (min tokens per image is 64), supports a maximum video input of 1280 frames, and optimizes the inference capability for long videos.\n",
    "\n",
    "Here are a few simple examples to quickly show you how to leverage the Seed1.5-VL for video understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78392a4-8786-464a-b155-934fed25dfa1",
   "metadata": {},
   "source": [
    "### 0. Setup the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97565d",
   "metadata": {},
   "source": [
    "#### Pre-requisite\n",
    "- API Key: [Obtain an API key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey) for the Seed-1.8 model.\n",
    "- Model Endpoint: Ensure the base URL of the Ark API.\n",
    "- Activate the Model: Activate the Seed-1.8 model in [the Ark Console](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement).\n",
    "- Install Dependencies: Install required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a7a309",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://bytedpypi.byted.org/simple/\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 2)) (10.2.0)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 3)) (2.7.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 4)) (4.11.0.86)\n",
      "Requirement already satisfied: supervision==0.27.0 in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: ui-tars in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 7)) (0.4.4)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 8)) (0.9.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 9)) (2.9.1)\n",
      "Requirement already satisfied: volcengine-python-sdk[ark] in /usr/local/lib/python3.11/dist-packages (from -r ../requirements.txt (line 5)) (4.0.43)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from supervision==0.27.0->-r ../requirements.txt (line 6)) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision==0.27.0->-r ../requirements.txt (line 6)) (1.16.2)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision==0.27.0->-r ../requirements.txt (line 6)) (3.10.6)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision==0.27.0->-r ../requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision==0.27.0->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision==0.27.0->-r ../requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r ../requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r ../requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r ../requirements.txt (line 1)) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r ../requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r ../requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r ../requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r ../requirements.txt (line 3)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r ../requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r ../requirements.txt (line 3)) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai->-r ../requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from volcengine-python-sdk[ark]->-r ../requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.16 in /usr/lib/python3/dist-packages (from volcengine-python-sdk[ark]->-r ../requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from volcengine-python-sdk[ark]->-r ../requirements.txt (line 5)) (46.0.3)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ui-tars->-r ../requirements.txt (line 7)) (4.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (3.16.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r ../requirements.txt (line 9)) (3.5.1)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography>=44.0.1->volcengine-python-sdk[ark]->-r ../requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision==0.27.0->-r ../requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision==0.27.0->-r ../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision==0.27.0->-r ../requirements.txt (line 6)) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision==0.27.0->-r ../requirements.txt (line 6)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision==0.27.0->-r ../requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.6.0->supervision==0.27.0->-r ../requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->-r ../requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r ../requirements.txt (line 9)) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ui-tars->-r ../requirements.txt (line 7)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ui-tars->-r ../requirements.txt (line 7)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ui-tars->-r ../requirements.txt (line 7)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ui-tars->-r ../requirements.txt (line 7)) (0.22.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography>=44.0.1->volcengine-python-sdk[ark]->-r ../requirements.txt (line 5)) (2.22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dffc3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "# Please set the API key here\n",
    "import os\n",
    "\n",
    "os.environ['ARK_API_KEY']  = 'your_ark_api_key'\n",
    "os.environ['ARK_MODEL_ENDPOINT'] = '\"doubao-seed-1-8-251215\"\n",
    "base_url = \"https://ark.cn-beijing.volces.com/api/v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9a4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from enum import Enum\n",
    "import os\n",
    "import base64\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "from video_processing import process_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e54d43-9f95-418a-a7ed-e1b418965516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please set the API key here\n",
    "client = OpenAI(\n",
    "    base_url=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "    api_key=os.environ.get(\"ARK_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33aad48-c939-4bf3-beef-9b5efc7d442b",
   "metadata": {},
   "source": [
    "#### Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(video_path,\n",
    "                     sampling_fps=1,\n",
    "                     max_frames=1280,\n",
    "                     max_video_length=81920):\n",
    "    if not os.path.exists(video_path):\n",
    "        raise ValueError('Video file does not exist.')\n",
    "    with open(video_path, 'rb') as f:\n",
    "        video_bytes = f.read()\n",
    "\n",
    "    video_base64_list, timestamps, _ = process_video(video_bytes, sampling_fps,\n",
    "                                                     max_frames,\n",
    "                                                     max_video_length)\n",
    "    return video_base64_list, timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_video_message(prompt, video_frames, video_timestamps):\n",
    "    \"\"\"\n",
    "    Construct a message for video understanding.\n",
    "    \"\"\"\n",
    "    video_contents = []\n",
    "    for image_bytes, timestamp in zip(video_frames, video_timestamps):\n",
    "        video_contents.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f'[{round(timestamp, 1)} second]'\n",
    "        })\n",
    "        video_contents.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{image_bytes}\",\n",
    "        })\n",
    "    contents = video_contents + [{\"type\": \"text\", \"text\": prompt}]\n",
    "    message = [{\"role\": \"user\", \"content\": contents}]\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send request to API to get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_complete(client, messages):\n",
    "    response = client.chat.completions.create(model=os.environ['ARK_MODEL_ENDPOINT'],\n",
    "                                              messages=messages,\n",
    "                                              reasoning_effort=\"medium\",\n",
    "                                              stream=False,\n",
    "                                              max_completion_tokens=65536)\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05c7f0-6b26-4b51-99c2-5658a277881d",
   "metadata": {},
   "source": [
    "### 1. General Video Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48fd468-12d6-46c9-ae19-c2c981bdc6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[video] 22.4 second video, sampling 22 frames, 384 tokens per frame\n",
      "Seed-1.8:\n",
      "<think>Got it, let's break this video down step by step, two attempts by the female high jumper.\n",
      "\n",
      "First attempt:\n",
      "0.0s-3.0s: The blonde female athlete in a yellow/brown track suit starts her approach run down the blue track, gradually picking up speed.\n",
      "3.0s-7.0s: She sprints down the runway, maintaining form as she nears the high jump bar.\n",
      "7.0s-8.5s: She launches into her jump, arching over the bar successfully.\n",
      "8.5s-11.5s: She lands on the large UCS high jump mat, then stands up and walks off the mat, while an official to the right holds up a red flag (probably indicating... wait no, wait the second attempt, wait no first attempt flag is red? Wait no, let's go to second attempt.\n",
      "\n",
      "12.0s-16.0s: The athlete starts her second approach run down the track again, getting into sprint rhythm.\n",
      "16.0s-19.0s: She sprints towards the bar, plants her takeoff foot, and launches into the jump, again clearing the bar with her arched body.\n",
      "19.0s-22.0s: She lands on the mat, stands up, and walks off as the official again holds up the red flag (likely signaling a failed attempt? Wait no, wait maybe the flag is for something else, but the video shows two consecutive jumps by her, both clearing the bar visually, then the official's red flag each time. Wait, the video ends with her walking off the mat the second time.\n",
      "\n",
      "Also, the background has other athletes, officials sitting/standing, a Gatorade cooler cart, spectators by the track brick wall area.</think>\n",
      "This video shows a female high jumper completing two consecutive attempts at a track and field meet:\n",
      "\n",
      "1.  **First jump attempt (0.0s to ~11.5s):**\n",
      "    The blonde athlete in a yellow and brown track suit begins her approach run down the blue track, accelerating as she sprints toward the high jump bar. She plants her takeoff foot, launches into the air, and successfully arches her body over the bar. She lands cleanly on the large UCS branded high jump mat, stands up, and walks off the landing pad as an official to the right holds up a red flag.\n",
      "\n",
      "2.  **Second jump attempt (12.0s to 22.5s):**\n",
      "    The athlete starts another approach run down the track, building speed again. She sprints to the bar, executes her takeoff and arching jump once more to clear the bar, then lands on the mat. She stands up and walks off the landing pad, with the official again holding up the red flag as the video ends.\n",
      "\n",
      "Throughout the video, other athletes, officials, and spectators are visible around the track area, with a Gatorade cooler cart set up near the spectator benches.\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/demo1.mp4\"\n",
    "text_prompts = \"Describe this video in details.\"\n",
    "# sampling video frames\n",
    "sampling_fps = 1\n",
    "sampled_frames, timestamps = preprocess_video(video_path)\n",
    "message = construct_video_message(prompt=text_prompts, video_timestamps=timestamps, video_frames=sampled_frames)\n",
    "result = api_complete(client, message)\n",
    "response = result.content\n",
    "reasoning_content = result.reasoning_content\n",
    "print(\"Seed-1.8:\\n<think>{}</think>\\n{}\".format(reasoning_content, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ce570-7ac2-4c58-9de2-aea4c4e2954a",
   "metadata": {},
   "source": [
    "### 2. Video Temporal Grounding\n",
    "The Seed-1.8 has powerful video temporal grounding capabilities (single segment or multiple segments). Based on user prompts, it can locate the corresponding segments within the video and output them in the format of start and end seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89845b90-e976-45c1-84cd-7239963101ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[video] 22.4 second video, sampling 44 frames, 384 tokens per frame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-1.8:\n",
      " <think>用户现在需要知道视频里两次跳高的起止时间，第一次是0.0到8.1秒，第二次是11.8到19.7秒。先看第一次：00:00开始助跑，到00:08完成过杆；第二次00:11开始助跑，00:19完成过杆。整理一下。</think>\n",
      "第一次跳高：00:00-00:08（从助跑开始到完成过杆落地）\n",
      "第二次跳高：00:11-00:19（从助跑开始到完成过杆落地）\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/demo1.mp4\"\n",
    "text_prompts = \"请输出视频中女人每一次跳高的精确起止时间，如果有多次，请分别输出每一次的起止时间\"\n",
    "# sampling video frames\n",
    "sampling_fps = 2\n",
    "sampled_frames, timestamps = preprocess_video(video_path, sampling_fps=2)\n",
    "message = construct_video_message(prompt=text_prompts, video_timestamps=timestamps, video_frames=sampled_frames)\n",
    "result = api_complete(client, message)\n",
    "response = result.content\n",
    "reasoning_content = result.reasoning_content\n",
    "print(\"Seed-1.8:\\n\", \"<think>{}</think>\\n{}\".format(reasoning_content, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7521df-55b1-4d97-b846-6aa79e9762b3",
   "metadata": {},
   "source": [
    "### 3. Dense Video Captioning\n",
    "Building upon its temporal grounding capabilities, the model exhibits time perception ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c4fbac9-5c82-447b-b174-bec330bd70df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[video] 22.4 second video, sampling 22 frames, 384 tokens per frame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-1.8:\n",
      "<think>Got it, let's look at the video step by step.\n",
      "\n",
      "First attempt:\n",
      "0.0 to 7.0 seconds: The female athlete starts her run-up towards the high jump bar.\n",
      "7.0 to 10.0 seconds: She jumps over the bar and lands on the mat, then gets up.\n",
      "10.0 to 12.0 seconds: She walks off the mat after the first attempt.\n",
      "\n",
      "Second attempt:\n",
      "12.5 to 18.0 seconds: She starts her second run-up towards the high jump bar.\n",
      "18.0 to 20.5 seconds: She jumps over the bar again, lands on the mat, and gets up.\n",
      "20.5 to 22.3 seconds: She walks off the mat after the second attempt.</think>\n",
      "0.0 - 7.0 second: A female athlete begins her run-up for the high jump attempt.\n",
      "7.0 - 10.5 second: The athlete jumps over the high jump bar, lands on the mat and stands up.\n",
      "10.5 - 12.5 second: The athlete walks off the high jump mat after the first try.\n",
      "12.5 - 18.0 second: The athlete starts her second run-up for another high jump attempt.\n",
      "18.0 - 20.5 second: The athlete jumps over the high jump bar again, lands on the mat and stands up.\n",
      "20.5 - 22.3 second: The athlete walks off the high jump mat after the second attempt.\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/demo1.mp4\"\n",
    "text_prompts = \"Please watch this video carefully and find out all key events in this video, and output the events along with the start/end timestamps using second format.\"\n",
    "sampling_fps = 2\n",
    "sampled_frames, timestamps = preprocess_video(video_path)\n",
    "message = construct_video_message(prompt=text_prompts, video_timestamps=timestamps, video_frames=sampled_frames)\n",
    "result = api_complete(client, message)\n",
    "response = result.content\n",
    "reasoning_content = result.reasoning_content\n",
    "print(\"Seed-1.8:\\n<think>{}</think>\\n{}\".format(reasoning_content, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d99a74-6eaf-4b7f-aac4-c3fb2059736f",
   "metadata": {},
   "source": [
    "### 4. Video Spatiotemporal Grounding\n",
    "Seed-1.8 has expanded spatiotemporal grounding capabilities based on Seed-1.5-VL. Given text or image prompts, the model can output the start and end timestamps as well as corresponding localization coordinates (`<bbox>` or `<point>`) of the target in the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = \"When and where does '{text}' occur? Return temporal and spatial boundaries.\"\n",
    "SPATIOTEMPORAL_PROMPT = \"\"\"Output a JSON list of timestamps (seconds) with associated bounding boxes.\n",
    "\n",
    "Example:\n",
    "{\n",
    "  \"9.0 second\": [\n",
    "      {\"bbox\": \"<bbox>71 26 178 239</bbox>\"}\n",
    "  ],\n",
    "  \"10.0 second\": [\n",
    "      {\"bbox\": \"<bbox>63 24 170 239</bbox>\"}\n",
    "  ],\n",
    "  ...\n",
    "  \"39.0 second\": [\n",
    "      {\"bbox\": \"<bbox>64 3 187 233</bbox>\"}\n",
    "  ],\n",
    "  \"40.0 second\": [\n",
    "      {\"bbox\": \"<bbox>93 19 187 231</bbox>\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Focus on:\n",
    "- giving exact timestamps (seconds)\n",
    "- returning <bbox>x1 y1 x2 y2</bbox> box coordinates\n",
    "- only including frames where the object clearly appears\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[video] 22.4 second video, sampling 22 frames, 384 tokens per frame\n",
      "Seed-1.8:\n",
      "<think>Got it, let's see. Starting from 5.0 second, the man appears:\n",
      "\n",
      "5.0 second: <bbox>938 605 999 999</bbox>\n",
      "6.0 second: <bbox>680 577 770 999</bbox>\n",
      "7.0 second: <bbox>934 608 999 999</bbox>\n",
      "8.0 second: <bbox>932 598 999 999</bbox>\n",
      "9.0 second: <bbox>896 566 987 999</bbox>\n",
      "10.0 second: <bbox>881 564 980 972</bbox>\n",
      "11.0 second: <bbox>854 564 968 961</bbox>\n",
      "18.0 second: <bbox>820 577 926 999</bbox>\n",
      "19.0 second: <bbox>929 575 999 999</bbox>\n",
      "20.0 second: <bbox>850 580 958 999</bbox>\n",
      "21.0 second: <bbox>826 569 941 999</bbox>\n",
      "22.0 second: <bbox>780 556 879 945</bbox></think>\n",
      "{\"5.0 second\": [{\"bbox\": \"<bbox>938 605 999 999</bbox>\"}], \"6.0 second\": [{\"bbox\": \"<bbox>680 577 770 999</bbox>\"}], \"7.0 second\": [{\"bbox\": \"<bbox>934 608 999 999</bbox>\"}], \"8.0 second\": [{\"bbox\": \"<bbox>932 598 999 999</bbox>\"}], \"9.0 second\": [{\"bbox\": \"<bbox>896 566 987 999</bbox>\"}], \"10.0 second\": [{\"bbox\": \"<bbox>881 564 980 972</bbox>\"}], \"11.0 second\": [{\"bbox\": \"<bbox>854 564 968 961</bbox>\"}], \"18.0 second\": [{\"bbox\": \"<bbox>820 577 926 999</bbox>\"}], \"19.0 second\": [{\"bbox\": \"<bbox>929 575 999 999</bbox>\"}], \"20.0 second\": [{\"bbox\": \"<bbox>850 580 958 999</bbox>\"}], \"21.0 second\": [{\"bbox\": \"<bbox>826 569 941 999</bbox>\"}], \"22.0 second\": [{\"bbox\": \"<bbox>780 556 879 945</bbox>\"}]}\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/demo1.mp4\"\n",
    "\n",
    "text = \"举红色旗子的男人\"\n",
    "text_prompts = question_template.format(text=text) + \"\\n\"+ SPATIOTEMPORAL_PROMPT\n",
    "# sampling video frames\n",
    "sampling_fps = 1\n",
    "sampled_frames, timestamps = preprocess_video(video_path, sampling_fps=sampling_fps)\n",
    "message = construct_video_message(prompt=text_prompts, video_timestamps=timestamps, video_frames=sampled_frames)\n",
    "result = api_complete(client, message)\n",
    "response = result.content\n",
    "reasoning_content = result.reasoning_content\n",
    "print(\"Seed-1.8:\\n<think>{}</think>\\n{}\".format(reasoning_content, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "142ee278-0782-4dbf-a845-eec5c85f17ee",
  "filePath": "/mnt/bn/ic-vlm/personal/chengtianheng/Seed-1.8/Video/video_understanding.ipynb",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
